{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: RCall.jl: ── Attaching packages ─────────────────────────────────────── tidyverse 1.2.1 ──\n",
      "│ ✔ ggplot2 3.1.0       ✔ purrr   0.3.2  \n",
      "│ ✔ tibble  2.1.1       ✔ dplyr   0.8.0.1\n",
      "│ ✔ tidyr   0.8.3       ✔ stringr 1.4.0  \n",
      "│ ✔ readr   1.3.1       ✔ forcats 0.4.0  \n",
      "│ ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "│ ✖ dplyr::filter() masks stats::filter()\n",
      "│ ✖ dplyr::lag()    masks stats::lag()\n",
      "└ @ RCall /home/mauriciogtec/.julia/packages/RCall/iojZI/src/io.jl:113\n"
     ]
    }
   ],
   "source": [
    "using Pkg; Pkg.activate(\"..\")\n",
    "using Revise\n",
    "using Distributions\n",
    "import StatsBase.weights\n",
    "using Random\n",
    "using RCall\n",
    "using ProgressBars\n",
    "using GraphFusedLasso\n",
    "using FileIO\n",
    "using DataFrames, CSV\n",
    "using Printf\n",
    "\n",
    "R\"library('tidyverse')\"\n",
    "\n",
    "# Random.seed!(418916);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_benchmarks (generic function with 1 method)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function generate_task_dynamic(task, N)\n",
    "#     cuts = [N ÷ 3, 2(N ÷ 3)]\n",
    "    cuts = sort(sample(2:N-1, 2, replace=false))\n",
    "    x1 = 1:cuts[1]\n",
    "    x2 = (cuts[1] + 1):cuts[2]\n",
    "    x3 = (cuts[2] + 1):N\n",
    "    x = [x1; x2; x3]\n",
    "    \n",
    "    values1 = 2.0(rand(Uniform(), 4) .- 0.5)\n",
    "\n",
    "    if task == \"smooth\"\n",
    "        y1 = values1[1] .+ (values1[2] - values1[1]) .* (x1 ./ cuts[1])\n",
    "        y2 = values1[2] .+ (values1[3] - values1[2]) .* (x2 .- cuts[1]) ./ (cuts[2] - cuts[1])\n",
    "        y3 = values1[3] .+ (values1[4] - values1[3]) .* (x3 .- cuts[2]) ./ (N - cuts[2])\n",
    "    elseif task == \"constant\"\n",
    "        y1 = fill(values1[1], cuts[1])\n",
    "        y2 = fill(values1[2], cuts[2] - cuts[1])\n",
    "        y3 = fill(values1[3], N - cuts[2])\n",
    "    elseif task == \"mixed\" || task == \"mixed+outliers\"\n",
    "        y1 = values1[1] .+ Int(rand() < 0.5) .* (values1[2] - values1[1]) .* (x1 ./ cuts[1])\n",
    "        y2 = values1[2] .+ Int(rand() < 0.5) .* (values1[3] - values1[2]) .* (x2 .- cuts[1]) ./ (cuts[2] - cuts[1])\n",
    "        y3 = values1[3] .+ Int(rand() < 0.5) .* (values1[4] - values1[3]) .* (x3 .- cuts[2]) ./ (N - cuts[2])\n",
    "    else\n",
    "        throw(ArgumentError)\n",
    "    end\n",
    "    μ = [y1; y2; y3]\n",
    "    return μ\n",
    "end\n",
    "\n",
    "function generate_task_dynamic(task, N, pmiss, σ)  \n",
    "    μ1 = generate_mu_task(task, N)\n",
    "    μ2 = generate_mu_task(task, N)\n",
    "    \n",
    "    evalpts = collect(range(-2.5, 2.5, length=100))\n",
    "    dmodels = [MixtureModel([Normal(μ1[i], σ), Normal(μ2[i], σ)])\n",
    "                 for i in 1:N]\n",
    "    devals = [pdf.(d, evalpts) for d in dmodels];\n",
    "    ndata = [sample([0, 10], weights([pmiss, 1.0 - pmiss])) for d in dmodels]\n",
    "    y = [rand(d, n) for (d, n) in zip(dmodels, ndata)]\n",
    "    \n",
    "    if task == \"mixed+ouliers\"\n",
    "        Nobs = sum([1 for n in ndata if n > 0])\n",
    "        K = floor(Nobs * 0.5)\n",
    "        idx = sample([i for (i, n) in enumerate(ndata) if n > 0], K, replace=false)\n",
    "        for i in idx\n",
    "            j = rand(1:length(y[i]))\n",
    "            y[i][j] += rand([-1, 1]) * 5.0\n",
    "        end\n",
    "    end\n",
    "                    \n",
    "    ptr = collect(1:N)\n",
    "    brks = [1, N + 1]\n",
    "    \n",
    "    return Dict(\"evalpts\" => evalpts,\n",
    "                \"dmodels\" => dmodels,\n",
    "                \"devals\" => devals,\n",
    "                \"y\" => y,\n",
    "                \"ndata\" => ndata,\n",
    "                \"mean1\" => μ1,\n",
    "                \"mean2\" => μ2,\n",
    "                \"values1\" => values1,\n",
    "                \"values2\" => values2,\n",
    "                \"ptr\" => ptr,\n",
    "                \"brks\" => brks)\n",
    "end\n",
    "\n",
    "function generate_bivariate_task(task1, task2, N, pmiss, σ=0.3, outliers=false)\n",
    "    μ1s = generate_task_dynamic(task1, N)\n",
    "    μ2s = generate_task_dynamic(task1, N)\n",
    "    ts =  generate_task_dynamic(task2, N)\n",
    "    \n",
    "    evalpts = range(-2.5, 2.5, length=100)\n",
    "    \n",
    "    μs = [(t + μ1, t + μ2) for (μ1, μ2) in zip(μ1s, μ2s), t in ts]\n",
    "    dmodels = [MixtureModel([Normal(μ1, σ), Normal(μ2, σ)]) for (μ1, μ2) in μs]\n",
    "\n",
    "    devals = [pdf.(d, evalpts) for d in dmodels];\n",
    "    ndata = [sample([0, 10], weights([pmiss, 1.0 - pmiss])) for d in dmodels]\n",
    "    y = [rand(d, n) for (d, n) in zip(dmodels, ndata)]\n",
    "    \n",
    "    if outliers\n",
    "        Nobs = sum([1 for n in ndata if n > 0])\n",
    "        K = floor(Nobs * 0.5)\n",
    "        idx = sample([i for (i, n) in enumerate(ndata) if n > 0], K, replace=false)\n",
    "        for i in idx\n",
    "            j = rand(1:length(y[i]))\n",
    "            y[i][j] += rand([-1, 1]) * 5.0\n",
    "        end\n",
    "    end\n",
    "                    \n",
    "    # make matrix pts\n",
    "    xrange = collect(1:N)\n",
    "    # temporal\n",
    "    ptr = []\n",
    "    brks = [1]\n",
    "    for i in 1:N\n",
    "        append!(ptr, xrange .+ (i - 1) * N)\n",
    "        push!(brks, brks[end] + N)\n",
    "    end\n",
    "    istemporal = fill(true, N^2)\n",
    "    # spatial\n",
    "    xrange = [(i - 1) * N + 1 for i in 1:N]\n",
    "    for i in 1:N\n",
    "        append!(ptr, xrange .+ (i - 1))\n",
    "        push!(brks, brks[end] + N)\n",
    "    end\n",
    "    append!(istemporal, fill(false, N^2))\n",
    "    \n",
    "    return Dict(\"evalpts\" => evalpts,\n",
    "                \"dmodels\" => dmodels,\n",
    "                \"devals\" => devals,\n",
    "                \"y\" => y,\n",
    "                \"ndata\" => ndata,\n",
    "                \"mean1\" => μ1s,\n",
    "                \"mean2\" => μ2s,\n",
    "                \"t\" => ts,\n",
    "                \"means\" => μs,\n",
    "                \"ptr\" => ptr,\n",
    "                \"brks\" => brks,\n",
    "                \"istemporal\" => istemporal)\n",
    "end\n",
    "\n",
    "# function for cross-validation fit\n",
    "\n",
    "function generate_cvsets(y, nsplits)\n",
    "    # make the cv splits\n",
    "    N = length(y)\n",
    "    cvsets = [Set{Int}() for i in 1:nsplits]\n",
    "    iobs = shuffle([i for (i, yi) in enumerate(y) if !isempty(yi)])\n",
    "    Nobs = length(iobs)\n",
    "    splitsize = Nobs ÷ nsplits\n",
    "    for k in 1:nsplits\n",
    "        for i in ((k - 1) * splitsize + 1):(k * splitsize)\n",
    "            push!(cvsets[k], iobs[i])\n",
    "        end\n",
    "    end\n",
    "    return cvsets\n",
    "end\n",
    "               \n",
    "                \n",
    "function fit(ytrain, ptr, brks, λ1, λ2)\n",
    "    N = length(ytrain)\n",
    "    lambdasl1 = fill(λ1, N)\n",
    "    lambdasl2 = fill(λ2, N)\n",
    "\n",
    "    # create the tree\n",
    "    M  = 33\n",
    "    splits = collect(range(-2.5, 2.5, length=M))\n",
    "    tree = DensityTree(splits)\n",
    "    bins2counts = Dict()\n",
    "    for (j, (li, ui)) in enumerate([tree.bins; [(i, i+1) for i in 1:M-1]])\n",
    "        lower = splits[li]\n",
    "        upper = splits[ui]\n",
    "        k = [sum(lower .< yi .< upper) for yi in ytrain]\n",
    "        bins2counts[(li, ui)] = k\n",
    "    end\n",
    "            \n",
    "    # fit binomial model in each tree\n",
    "    beta = zeros(N, M - 2)\n",
    "    for j in 1:M - 2\n",
    "        li, ui = tree.bins[j]\n",
    "        mi = (ui + li) ÷ 2 \n",
    "        parent_counts = bins2counts[(li, ui)] .+ 0.1\n",
    "        left_counts = bins2counts[(li, mi)]  .+ 0.05\n",
    "\n",
    "        lambdasl1 = fill(λ1, N)\n",
    "        lambdasl2 = fill(λ2, N)\n",
    "        model = BinomialEnet(\n",
    "            ptr, brks, lambdasl1, lambdasl2;\n",
    "            abstol=0.0, reltol=1e-4)\n",
    "        fit!(model, left_counts, parent_counts; steps=1000)\n",
    "\n",
    "        beta[:, j] = model.beta\n",
    "    end\n",
    "    tree.beta = beta\n",
    "    return tree\n",
    "end\n",
    "\n",
    "\n",
    "function fit2(ytrain, ptr, brks, λ1, λ2, η1, η2)\n",
    "    N = length(ytrain)\n",
    "    lambdasl1 = fill(λ1, N)\n",
    "    lambdasl2 = fill(λ2, N)\n",
    "\n",
    "    # create the tree\n",
    "    M  = 33\n",
    "    splits = collect(range(-2.5, 2.5, length=M))\n",
    "    tree = DensityTree(splits)\n",
    "    bins2counts = Dict()\n",
    "    for (j, (li, ui)) in enumerate([tree.bins; [(i, i+1) for i in 1:M-1]])\n",
    "        lower = splits[li]\n",
    "        upper = splits[ui]\n",
    "        k = [sum(lower .< yi .< upper) for yi in ytrain]\n",
    "        bins2counts[(li, ui)] = k\n",
    "    end\n",
    "            \n",
    "    # fit binomial model in each tree\n",
    "    beta = zeros(N, M - 2)\n",
    "    for j in 1:M - 2\n",
    "        li, ui = tree.bins[j]\n",
    "        mi = (ui + li) ÷ 2 \n",
    "        parent_counts = bins2counts[(li, ui)] .+ 0.1\n",
    "        left_counts = bins2counts[(li, mi)]  .+ 0.05\n",
    "\n",
    "        lambdasl1 = fill(λ1, N)\n",
    "        lambdasl2 = fill(λ2, N)\n",
    "        model = BinomialEnet(\n",
    "            ptr, brks, lambdasl1, lambdasl2;\n",
    "            abstol=0.0, reltol=1e-4)\n",
    "        fit!(model, left_counts, parent_counts; steps=1000)\n",
    "\n",
    "        beta[:, j] = model.beta\n",
    "    end\n",
    "    tree.beta = beta\n",
    "    return tree\n",
    "end\n",
    "\n",
    "                \n",
    "function integrated_squared_error(d1, d2, evalpts)\n",
    "    f = (d1 .- d2) .^ 2\n",
    "    δ = evalpts[2] .- evalpts[1]\n",
    "    return δ * (0.5f[1] + 0.5f[2] + sum(f[2:end-1]))\n",
    "end\n",
    "         \n",
    "function integrated_abs_error(d1, d2, evalpts)\n",
    "    f = abs.(d1 .- d2)\n",
    "    δ = evalpts[2] .- evalpts[1]\n",
    "    return δ * (0.5f[1] + 0.5f[2] + sum(f[2:end-1]))\n",
    "end\n",
    "         \n",
    "                \n",
    "function cv_fit(y, evalpts, ptr, brks, lambdas, cvsets, devals)\n",
    "    # for each cv split get the mse error\n",
    "    N = length(y)\n",
    "    nsplits = length(cvsets)\n",
    "    nlambdas = length(lambdas)\n",
    "    test_likelihood = zeros(nlambdas)\n",
    "                    \n",
    "    # prepare the tree structure and the bint \n",
    "    for (k, (λ1, λ2)) in enumerate(lambdas)\n",
    "        for i in 1:nsplits\n",
    "            # get the cv vector with missing data\n",
    "            ytrain = [j in cvsets[i] ? Float64[] : yi\n",
    "                      for (j, yi) in enumerate(y)]\n",
    "\n",
    "            tree = fit(ytrain, ptr, brks, λ1, λ2)               \n",
    "                            \n",
    "            # compute the out-of-sample likelihood\n",
    "            Ntest = 0.0\n",
    "            likelihood = 0.0\n",
    "            for j in collect(cvsets[i])\n",
    "                test_eval = y[j]\n",
    "                Ntest += length(test_eval)\n",
    "                likelihood += sum(predict(tree, sort(test_eval))[j])\n",
    "            end\n",
    "            likelihood /= Ntest\n",
    "                             \n",
    "            test_likelihood[k] += likelihood / nsplits\n",
    "            dhats = predict(tree, evalpts)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # now choose the best lambdas\n",
    "    best_lambdas = lambdas[argmax(test_likelihood)]\n",
    "    best_likelihood = maximum(test_likelihood)\n",
    "\n",
    "    # train for best params\n",
    "    best_tree = fit(y, ptr, brks, best_lambdas[1], best_lambdas[2])\n",
    "    densities = predict(best_tree, evalpts)\n",
    "    rmise = 0.0\n",
    "    miae = 0.0\n",
    "    for (d1, d2) in zip(devals, densities)\n",
    "        rmise += integrated_squared_error(d1, d2, evalpts)\n",
    "        miae += integrated_abs_error(d1, d2, evalpts)\n",
    "    end\n",
    "    rmise = sqrt(rmise / N)\n",
    "    miae = miae / N\n",
    "\n",
    "    return Dict(\"best_lambdas\" => best_lambdas,\n",
    "                \"cv_likelihood\" => best_likelihood,\n",
    "                \"densities\" => densities,\n",
    "                \"rmise\" => rmise,\n",
    "                \"miae\" => miae)\n",
    "end\n",
    "            \n",
    "function get_lambdas(method)\n",
    "    lambdas_dict = Dict(\n",
    "        \"fl\" => [(l, 1e-12) for l in range(1e-12, 3.0, length=25)],\n",
    "        \"kal\" => [(1e-12, l) for l in range(1e-12, 30.0, length=25)],\n",
    "        \"enet\" => [(l1, l2) for l1 in range(1e-12, 2.5, length=10)\n",
    "                            for l2 in range(1e-12, 25.0, length=10)]) \n",
    "    return lambdas_dict[method]\n",
    "end\n",
    "            \n",
    "function run_benchmarks(N, σ, pmiss;\n",
    "                        nsims=100,\n",
    "                        nsplits=5,\n",
    "                        tasks=(\"constant\", \"smooth\", \"mixed\", \"mixed+outliers\"))\n",
    "\n",
    "    experiment_results = []\n",
    "    for task in tasks\n",
    "        data = [generate_data(task, N, pmiss, σ) for _ in 1:nsims]\n",
    "        for method in (\"fl\", \"kal\", \"enet\")\n",
    "            println(\"Running task $task for method $method\")\n",
    "            lambdas = get_lambdas(method)\n",
    "            likelihood = zeros(nsims)\n",
    "            rmise = zeros(nsims)\n",
    "            miae = zeros(nsims)\n",
    "            for (l, D) in ProgressBar(enumerate(data))\n",
    "                y = D[\"y\"]\n",
    "                evalpts = D[\"evalpts\"]\n",
    "                ndata = D[\"ndata\"]\n",
    "                devals = D[\"devals\"]\n",
    "                ptr = D[\"ptr\"]\n",
    "                brks = D[\"brks\"]\n",
    "                cvsets = generate_cvsets(y, nsplits)\n",
    "\n",
    "                results = cv_fit(y, evalpts, ptr, brks, lambdas, cvsets, devals)\n",
    "\n",
    "                new_result = Dict(\n",
    "                    :experiment => l,\n",
    "                    :task => task,\n",
    "                    :method => method,\n",
    "                    :likelihood => results[\"cv_likelihood\"],\n",
    "                    :rmise => results[\"rmise\"],\n",
    "                    :miae => results[\"miae\"])\n",
    "                push!(experiment_results, new_result)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return experiment_results\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30×30 Array{Tuple{Float64,Float64},2}:\n",
       " (0.236837, -0.417602)     (0.395158, -0.259281)    …  (1.11343, 0.458987)   \n",
       " (0.244942, -0.355344)     (0.403263, -0.197023)       (1.12153, 0.521245)   \n",
       " (0.253047, -0.293086)     (0.411368, -0.134765)       (1.12964, 0.583503)   \n",
       " (0.261152, -0.230828)     (0.419473, -0.0725066)      (1.13774, 0.645761)   \n",
       " (0.269257, -0.16857)      (0.427578, -0.0102485)      (1.14585, 0.708019)   \n",
       " (0.277362, -0.106311)     (0.435683, 0.0520096)    …  (1.15395, 0.770278)   \n",
       " (0.285467, -0.128952)     (0.443788, 0.0293695)       (1.16206, 0.747637)   \n",
       " (0.261493, -0.151592)     (0.419815, 0.00672937)      (1.13808, 0.724997)   \n",
       " (0.23752, -0.174232)      (0.395841, -0.0159108)      (1.11411, 0.702357)   \n",
       " (0.213547, -0.196872)     (0.371868, -0.0385509)      (1.09014, 0.679717)   \n",
       " (0.189574, -0.219512)     (0.347895, -0.061191)    …  (1.06616, 0.657077)   \n",
       " (0.165601, -0.242152)     (0.323922, -0.0838312)      (1.04219, 0.634437)   \n",
       " (0.141627, -0.264792)     (0.299948, -0.106471)       (1.01822, 0.611797)   \n",
       " ⋮                                                  ⋱                        \n",
       " (-0.00221187, -0.400633)  (0.156109, -0.242312)       (0.874377, 0.475956)  \n",
       " (-0.0261851, -0.423273)   (0.132136, -0.264952)       (0.850404, 0.453316)  \n",
       " (-0.0501583, -0.445913)   (0.108163, -0.287592)    …  (0.826431, 0.430676)  \n",
       " (-0.0741315, -0.468554)   (0.0841896, -0.310232)      (0.802457, 0.408035)  \n",
       " (-0.0981047, -0.491194)   (0.0602164, -0.332873)      (0.778484, 0.385395)  \n",
       " (-0.122078, -0.573129)    (0.0362432, -0.414808)      (0.754511, 0.30346)   \n",
       " (-0.146051, -0.655065)    (0.01227, -0.496744)        (0.730538, 0.221524)  \n",
       " (-0.170024, -0.737001)    (-0.0117032, -0.57868)   …  (0.706565, 0.139588)  \n",
       " (-0.193998, -0.818936)    (-0.0356764, -0.660615)     (0.682591, 0.0576525) \n",
       " (-0.0153749, -0.900872)   (0.142946, -0.742551)       (0.861214, -0.0242832)\n",
       " (0.163248, -0.982808)     (0.321569, -0.824487)       (1.03984, -0.106219)  \n",
       " (0.34187, -1.06474)       (0.500191, -0.906422)       (1.21846, -0.188155)  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment = generate_bivariate_task(\"smooth\", \"smooth\", 30, 0.1)\n",
    "experiment[\"means\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running task smooth for method fl\n",
      "100.00%┣██████████████████████████████████████████████████████████████┫ 50/50 07:50<00:00, 0.10 it/s]\n",
      "Running task smooth for method kal\n",
      "100.00%┣██████████████████████████████████████████████████████████████┫ 50/50 07:50<00:00, 0.10 it/s]\n",
      "Running task smooth for method enet\n",
      "100.00%┣██████████████████████████████████████████████████████████████┫ 50/50 54:50<00:00, 0.01 it/s]\n",
      "Running task constant for method fl\n",
      "100.00%┣██████████████████████████████████████████████████████████████┫ 50/50 08:18<00:00, 0.10 it/s]\n",
      "Running task constant for method kal\n",
      "100.00%┣██████████████████████████████████████████████████████████████┫ 50/50 08:13<00:00, 0.10 it/s]\n",
      "Running task constant for method enet\n",
      "100.00%┣██████████████████████████████████████████████████████████████┫ 50/50 58:05<00:00, 0.01 it/s]\n",
      "Running task mixed for method fl\n",
      "100.00%┣██████████████████████████████████████████████████████████████┫ 50/50 08:04<00:00, 0.10 it/s]\n",
      "Running task mixed for method kal\n",
      "100.00%┣██████████████████████████████████████████████████████████████┫ 50/50 07:59<00:00, 0.10 it/s]\n",
      "Running task mixed for method enet\n",
      "100.00%┣██████████████████████████████████████████████████████████████┫ 50/50 55:48<00:00, 0.01 it/s]\n",
      "Running task mixed+outliers for method fl\n",
      "100.00%┣██████████████████████████████████████████████████████████████┫ 50/50 08:05<00:00, 0.10 it/s]\n",
      "Running task mixed+outliers for method kal\n",
      "100.00%┣██████████████████████████████████████████████████████████████┫ 50/50 08:07<00:00, 0.10 it/s]\n",
      "Running task mixed+outliers for method enet\n",
      "100.00%┣██████████████████████████████████████████████████████████████┫ 50/50 56:59<00:00, 0.01 it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "600-element Array{Any,1}:\n",
       " Dict{Symbol,Any}(:method=>\"fl\",:rmise=>0.287274,:task=>\"smooth\",:likelihood=>0.52963,:experiment=>1,:miae=>0.403404)            \n",
       " Dict{Symbol,Any}(:method=>\"fl\",:rmise=>0.365551,:task=>\"smooth\",:likelihood=>0.674995,:experiment=>2,:miae=>0.497785)           \n",
       " Dict{Symbol,Any}(:method=>\"fl\",:rmise=>0.315245,:task=>\"smooth\",:likelihood=>0.648937,:experiment=>3,:miae=>0.392976)           \n",
       " Dict{Symbol,Any}(:method=>\"fl\",:rmise=>0.259446,:task=>\"smooth\",:likelihood=>0.543999,:experiment=>4,:miae=>0.37407)            \n",
       " Dict{Symbol,Any}(:method=>\"fl\",:rmise=>0.320425,:task=>\"smooth\",:likelihood=>0.560123,:experiment=>5,:miae=>0.411986)           \n",
       " Dict{Symbol,Any}(:method=>\"fl\",:rmise=>0.340007,:task=>\"smooth\",:likelihood=>0.617697,:experiment=>6,:miae=>0.433046)           \n",
       " Dict{Symbol,Any}(:method=>\"fl\",:rmise=>0.36282,:task=>\"smooth\",:likelihood=>0.490645,:experiment=>7,:miae=>0.493204)            \n",
       " Dict{Symbol,Any}(:method=>\"fl\",:rmise=>0.263022,:task=>\"smooth\",:likelihood=>0.525978,:experiment=>8,:miae=>0.348088)           \n",
       " Dict{Symbol,Any}(:method=>\"fl\",:rmise=>0.263926,:task=>\"smooth\",:likelihood=>0.664618,:experiment=>9,:miae=>0.350197)           \n",
       " Dict{Symbol,Any}(:method=>\"fl\",:rmise=>0.274157,:task=>\"smooth\",:likelihood=>0.615198,:experiment=>10,:miae=>0.360178)          \n",
       " Dict{Symbol,Any}(:method=>\"fl\",:rmise=>0.327362,:task=>\"smooth\",:likelihood=>0.717374,:experiment=>11,:miae=>0.406198)          \n",
       " Dict{Symbol,Any}(:method=>\"fl\",:rmise=>0.296794,:task=>\"smooth\",:likelihood=>0.595124,:experiment=>12,:miae=>0.373561)          \n",
       " Dict{Symbol,Any}(:method=>\"fl\",:rmise=>0.342431,:task=>\"smooth\",:likelihood=>0.701915,:experiment=>13,:miae=>0.449776)          \n",
       " ⋮                                                                                                                               \n",
       " Dict{Symbol,Any}(:method=>\"enet\",:rmise=>0.360651,:task=>\"mixed+outliers\",:likelihood=>0.676412,:experiment=>39,:miae=>0.43295) \n",
       " Dict{Symbol,Any}(:method=>\"enet\",:rmise=>0.292601,:task=>\"mixed+outliers\",:likelihood=>0.47105,:experiment=>40,:miae=>0.417891) \n",
       " Dict{Symbol,Any}(:method=>\"enet\",:rmise=>0.270005,:task=>\"mixed+outliers\",:likelihood=>0.545875,:experiment=>41,:miae=>0.369442)\n",
       " Dict{Symbol,Any}(:method=>\"enet\",:rmise=>0.300992,:task=>\"mixed+outliers\",:likelihood=>0.571097,:experiment=>42,:miae=>0.454989)\n",
       " Dict{Symbol,Any}(:method=>\"enet\",:rmise=>0.364759,:task=>\"mixed+outliers\",:likelihood=>0.600593,:experiment=>43,:miae=>0.463284)\n",
       " Dict{Symbol,Any}(:method=>\"enet\",:rmise=>0.39107,:task=>\"mixed+outliers\",:likelihood=>0.55401,:experiment=>44,:miae=>0.46956)   \n",
       " Dict{Symbol,Any}(:method=>\"enet\",:rmise=>0.299754,:task=>\"mixed+outliers\",:likelihood=>0.633647,:experiment=>45,:miae=>0.384959)\n",
       " Dict{Symbol,Any}(:method=>\"enet\",:rmise=>0.304245,:task=>\"mixed+outliers\",:likelihood=>0.566426,:experiment=>46,:miae=>0.414001)\n",
       " Dict{Symbol,Any}(:method=>\"enet\",:rmise=>0.275355,:task=>\"mixed+outliers\",:likelihood=>0.713029,:experiment=>47,:miae=>0.345013)\n",
       " Dict{Symbol,Any}(:method=>\"enet\",:rmise=>0.344027,:task=>\"mixed+outliers\",:likelihood=>0.467731,:experiment=>48,:miae=>0.483921)\n",
       " Dict{Symbol,Any}(:method=>\"enet\",:rmise=>0.303145,:task=>\"mixed+outliers\",:likelihood=>0.674453,:experiment=>49,:miae=>0.390224)\n",
       " Dict{Symbol,Any}(:method=>\"enet\",:rmise=>0.342656,:task=>\"mixed+outliers\",:likelihood=>0.70039,:experiment=>50,:miae=>0.459853) "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 150\n",
    "σ = 0.3\n",
    "pmiss = 0.8\n",
    "nsims = 50\n",
    "tasks = (\"smooth\", \"constant\", \"mixed\", \"mixed+outliers\")\n",
    "\n",
    "experiment_results = run_benchmarks(N, σ, pmiss, nsims=nsims,tasks=tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(experiment = Int[],\n",
    "               task=String[],\n",
    "               method=String[],\n",
    "               likelihood=Float64[],\n",
    "               rmise=Float64[],\n",
    "               miae=Float64[])\n",
    "for record in experiment_results\n",
    "    push!(df, record)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>experiment</th><th>task</th><th>method</th><th>likelihood</th><th>rmise</th><th>miae</th></tr><tr><th></th><th>Int64</th><th>String</th><th>String</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><tr><th>1</th><td>1</td><td>smooth</td><td>fl</td><td>0.52963</td><td>0.287274</td><td>0.403404</td></tr><tr><th>2</th><td>2</td><td>smooth</td><td>fl</td><td>0.674995</td><td>0.365551</td><td>0.497785</td></tr><tr><th>3</th><td>3</td><td>smooth</td><td>fl</td><td>0.648937</td><td>0.315245</td><td>0.392976</td></tr><tr><th>4</th><td>4</td><td>smooth</td><td>fl</td><td>0.543999</td><td>0.259446</td><td>0.37407</td></tr><tr><th>5</th><td>5</td><td>smooth</td><td>fl</td><td>0.560123</td><td>0.320425</td><td>0.411986</td></tr><tr><th>6</th><td>6</td><td>smooth</td><td>fl</td><td>0.617697</td><td>0.340007</td><td>0.433046</td></tr><tr><th>7</th><td>7</td><td>smooth</td><td>fl</td><td>0.490645</td><td>0.36282</td><td>0.493204</td></tr><tr><th>8</th><td>8</td><td>smooth</td><td>fl</td><td>0.525978</td><td>0.263022</td><td>0.348088</td></tr><tr><th>9</th><td>9</td><td>smooth</td><td>fl</td><td>0.664618</td><td>0.263926</td><td>0.350197</td></tr><tr><th>10</th><td>10</td><td>smooth</td><td>fl</td><td>0.615198</td><td>0.274157</td><td>0.360178</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& experiment & task & method & likelihood & rmise & miae\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & smooth & fl & 0.52963 & 0.287274 & 0.403404 \\\\\n",
       "\t2 & 2 & smooth & fl & 0.674995 & 0.365551 & 0.497785 \\\\\n",
       "\t3 & 3 & smooth & fl & 0.648937 & 0.315245 & 0.392976 \\\\\n",
       "\t4 & 4 & smooth & fl & 0.543999 & 0.259446 & 0.37407 \\\\\n",
       "\t5 & 5 & smooth & fl & 0.560123 & 0.320425 & 0.411986 \\\\\n",
       "\t6 & 6 & smooth & fl & 0.617697 & 0.340007 & 0.433046 \\\\\n",
       "\t7 & 7 & smooth & fl & 0.490645 & 0.36282 & 0.493204 \\\\\n",
       "\t8 & 8 & smooth & fl & 0.525978 & 0.263022 & 0.348088 \\\\\n",
       "\t9 & 9 & smooth & fl & 0.664618 & 0.263926 & 0.350197 \\\\\n",
       "\t10 & 10 & smooth & fl & 0.615198 & 0.274157 & 0.360178 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×6 DataFrame\n",
       "│ Row │ experiment │ task   │ method │ likelihood │ rmise    │ miae     │\n",
       "│     │ \u001b[90mInt64\u001b[39m      │ \u001b[90mString\u001b[39m │ \u001b[90mString\u001b[39m │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mFloat64\u001b[39m  │ \u001b[90mFloat64\u001b[39m  │\n",
       "├─────┼────────────┼────────┼────────┼────────────┼──────────┼──────────┤\n",
       "│ 1   │ 1          │ smooth │ fl     │ 0.52963    │ 0.287274 │ 0.403404 │\n",
       "│ 2   │ 2          │ smooth │ fl     │ 0.674995   │ 0.365551 │ 0.497785 │\n",
       "│ 3   │ 3          │ smooth │ fl     │ 0.648937   │ 0.315245 │ 0.392976 │\n",
       "│ 4   │ 4          │ smooth │ fl     │ 0.543999   │ 0.259446 │ 0.37407  │\n",
       "│ 5   │ 5          │ smooth │ fl     │ 0.560123   │ 0.320425 │ 0.411986 │\n",
       "│ 6   │ 6          │ smooth │ fl     │ 0.617697   │ 0.340007 │ 0.433046 │\n",
       "│ 7   │ 7          │ smooth │ fl     │ 0.490645   │ 0.36282  │ 0.493204 │\n",
       "│ 8   │ 8          │ smooth │ fl     │ 0.525978   │ 0.263022 │ 0.348088 │\n",
       "│ 9   │ 9          │ smooth │ fl     │ 0.664618   │ 0.263926 │ 0.350197 │\n",
       "│ 10  │ 10         │ smooth │ fl     │ 0.615198   │ 0.274157 │ 0.360178 │"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head(df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 12 x 3\n",
      "# Groups:   task [4]\n",
      "   task           method likelihood_mean\n",
      "   <chr>          <chr>            <dbl>\n",
      " 1 constant       enet             0.309\n",
      " 2 constant       fl               0.302\n",
      " 3 constant       kal              0.312\n",
      " 4 mixed          enet             0.309\n",
      " 5 mixed          fl               0.309\n",
      " 6 mixed          kal              0.312\n",
      " 7 mixed+outliers enet             0.313\n",
      " 8 mixed+outliers fl               0.313\n",
      " 9 mixed+outliers kal              0.314\n",
      "10 smooth         enet             0.311\n",
      "11 smooth         fl               0.317\n",
      "12 smooth         kal              0.312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RObject{VecSxp}\n",
       "# A tibble: 12 x 3\n",
       "# Groups:   task [4]\n",
       "   task           method likelihood_mean\n",
       "   <chr>          <chr>            <dbl>\n",
       " 1 constant       enet             0.309\n",
       " 2 constant       fl               0.302\n",
       " 3 constant       kal              0.312\n",
       " 4 mixed          enet             0.309\n",
       " 5 mixed          fl               0.309\n",
       " 6 mixed          kal              0.312\n",
       " 7 mixed+outliers enet             0.313\n",
       " 8 mixed+outliers fl               0.313\n",
       " 9 mixed+outliers kal              0.314\n",
       "10 smooth         enet             0.311\n",
       "11 smooth         fl               0.317\n",
       "12 smooth         kal              0.312\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R\"\"\"\n",
    "df = $df %>% \n",
    "    group_by(task, method) %>%\n",
    "    summarize(likelihood_mean = mean(rmise))\n",
    "print(df)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"benchmarks-results-3.csv\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV.write(\"benchmarks-results-3.csv\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
