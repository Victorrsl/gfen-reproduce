{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg; Pkg.activate(\"..\")\n",
    "# Pkg.instantiate()\n",
    "using Distributions\n",
    "import StatsBase.weights\n",
    "using Random\n",
    "using RCall\n",
    "using ProgressBars\n",
    "using GraphFusedLasso\n",
    "using FileIO\n",
    "using DataFrames, CSV\n",
    "using Printf\n",
    "\n",
    "R\"library('tidyverse')\"\n",
    "\n",
    "# Random.seed!(418916);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_benchmarks (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function generate_trace(task, N)\n",
    "    cuts = [N ÷ 3, 2(N ÷ 3)]\n",
    "#     cuts = sort(sample(2:N-1, 2, replace=false))\n",
    "    x1 = 1:cuts[1]\n",
    "    x2 = (cuts[1] + 1):cuts[2]\n",
    "    x3 = (cuts[2] + 1):N\n",
    "    x = [x1; x2; x3]\n",
    "    \n",
    "    values1 = 2.0(rand(Uniform(), 4) .- 0.5)\n",
    "\n",
    "    if task == \"smooth\"\n",
    "        y1 = values1[1] .+ (values1[2] - values1[1]) .* (x1 ./ cuts[1])\n",
    "        y2 = values1[2] .+ (values1[3] - values1[2]) .* (x2 .- cuts[1]) ./ (cuts[2] - cuts[1])\n",
    "        y3 = values1[3] .+ (values1[4] - values1[3]) .* (x3 .- cuts[2]) ./ (N - cuts[2])\n",
    "    elseif task == \"constant\"\n",
    "        y1 = fill(values1[1], cuts[1])\n",
    "        y2 = fill(values1[2], cuts[2] - cuts[1])\n",
    "        y3 = fill(values1[3], N - cuts[2])\n",
    "    elseif task == \"mixed\"\n",
    "        y1 = values1[1] .+ Int(rand() < 0.5) .* (values1[2] - values1[1]) .* (x1 ./ cuts[1])\n",
    "        y2 = values1[2] .+ Int(rand() < 0.5) .* (values1[3] - values1[2]) .* (x2 .- cuts[1]) ./ (cuts[2] - cuts[1])\n",
    "        y3 = values1[3] .+ Int(rand() < 0.5) .* (values1[4] - values1[3]) .* (x3 .- cuts[2]) ./ (N - cuts[2])\n",
    "    else\n",
    "        throw(ArgumentError)\n",
    "    end\n",
    "    μ = [y1; y2; y3]\n",
    "    return μ\n",
    "end\n",
    "\n",
    "\n",
    "function generate_spt_task(task_space, task_time, N, pmiss; σ=0.3, outliers=false)\n",
    "    μ1s = generate_trace(task_space, N)\n",
    "    μ2s = generate_trace(task_space, N)\n",
    "    ts =  generate_trace(task_time, N)\n",
    "    \n",
    "    evalpts = collect(range(-2.5, 2.5, length=100))\n",
    "    \n",
    "    μs = [(t + μ1, t + μ2) for (μ1, μ2) in zip(μ1s, μ2s), t in ts]\n",
    "    dmodels = [MixtureModel([Normal(μ1, σ), Normal(μ2, σ)]) for (μ1, μ2) in μs]\n",
    "\n",
    "    devals = [pdf.(d, evalpts) for d in dmodels];\n",
    "    ndata = [sample([0, 10], weights([pmiss, 1.0 - pmiss])) for d in dmodels]\n",
    "    y = [rand(d, n) for (d, n) in zip(dmodels, ndata)]\n",
    "    \n",
    "    if outliers\n",
    "        Nobs = sum([1 for n in ndata if n > 0])\n",
    "        K = floor(Nobs * 0.5)\n",
    "        idx = sample([i for (i, n) in enumerate(ndata) if n > 0], K, replace=false)\n",
    "        for i in idx\n",
    "            j = rand(1:length(y[i]))\n",
    "            y[i][j] += rand([-1, 1]) * 5.0\n",
    "        end\n",
    "    end\n",
    "                    \n",
    "    # make matrix pts\n",
    "    xrange = collect(1:N)\n",
    "    # temporal\n",
    "    ptr = Int[]\n",
    "    brks = Int[1]\n",
    "    for i in 1:N\n",
    "        append!(ptr, xrange .+ (i - 1) * N)\n",
    "        push!(brks, brks[end] + N)\n",
    "    end\n",
    "    istemporal = fill(true, N^2)\n",
    "    # spatial\n",
    "    xrange = [(i - 1) * N + 1 for i in 1:N]\n",
    "    for i in 1:N\n",
    "        append!(ptr, xrange .+ (i - 1))\n",
    "        push!(brks, brks[end] + N)\n",
    "    end\n",
    "    append!(istemporal, fill(false, N^2))\n",
    "    \n",
    "    return Dict(\"evalpts\" => evalpts,\n",
    "                \"dmodels\" => dmodels,\n",
    "                \"devals\" => devals,\n",
    "                \"y\" => y,\n",
    "                \"ndata\" => ndata,\n",
    "                \"mean1\" => μ1s,\n",
    "                \"mean2\" => μ2s,\n",
    "                \"t\" => ts,\n",
    "                \"means\" => μs,\n",
    "                \"ptr\" => ptr,\n",
    "                \"brks\" => brks,\n",
    "                \"istemporal\" => istemporal)\n",
    "end\n",
    "\n",
    "# function for cross-validation fit\n",
    "\n",
    "function generate_cvsets(y, nsplits)\n",
    "    # make the cv splits\n",
    "    N = length(y)\n",
    "    cvsets = [Set{Int}() for i in 1:nsplits]\n",
    "    iobs = shuffle([i for (i, yi) in enumerate(y) if !isempty(yi)])\n",
    "    Nobs = length(iobs)\n",
    "    splitsize = Nobs ÷ nsplits\n",
    "    for k in 1:nsplits\n",
    "        for i in ((k - 1) * splitsize + 1):(k * splitsize)\n",
    "            push!(cvsets[k], iobs[i])\n",
    "        end\n",
    "    end\n",
    "    return cvsets\n",
    "end\n",
    "               \n",
    "\n",
    "\n",
    "function fit2(ytrain, ptr, brks, λ1, λ2, η1, η2, istemporal)\n",
    "    N = length(ytrain)\n",
    "    lambdasl1 = Float64[temp ? η1 : λ1 for temp in istemporal]\n",
    "    lambdasl2 = Float64[temp ? η2 : λ2 for temp in istemporal]\n",
    "\n",
    "    # create the tree\n",
    "    M  = 33\n",
    "    splits = collect(range(-2.5, 2.5, length=M))\n",
    "    tree = DensityTree(splits)\n",
    "    bins2counts = Dict()\n",
    "    for (j, (li, ui)) in enumerate([tree.bins; [(i, i+1) for i in 1:M-1]])\n",
    "        lower = splits[li]\n",
    "        upper = splits[ui]\n",
    "        k = [sum(lower .< yi .< upper) for yi in ytrain]\n",
    "        bins2counts[(li, ui)] = k\n",
    "    end\n",
    "            \n",
    "    # fit binomial model in each tree\n",
    "    beta = zeros(N, M - 2)\n",
    "    for j in 1:M - 2\n",
    "        li, ui = tree.bins[j]\n",
    "        level = Int(trunc(log2(j)))\n",
    "        mi = (ui + li) ÷ 2 \n",
    "        parent_counts = bins2counts[(li, ui)] .+ 0.1\n",
    "        left_counts = bins2counts[(li, mi)]  .+ 0.05\n",
    "\n",
    "        model = BinomialEnet(\n",
    "            ptr, brks,\n",
    "            lambdasl1 * (1 + level * sqrt(2)),\n",
    "            lambdasl2 * (1 + level * sqrt(2));\n",
    "            abstol=0.0, reltol=1e-4)\n",
    "        fit!(model, left_counts, parent_counts; steps=1000)\n",
    "\n",
    "        beta[:, j] = model.beta\n",
    "    end\n",
    "    tree.beta = beta\n",
    "    return tree\n",
    "end\n",
    "         \n",
    "                \n",
    "function cv_fit2(y, evalpts, ptr, brks, istemporal, lambdas, cvsets, models)\n",
    "    # for each cv split get the mse error\n",
    "    N = length(y)\n",
    "    nsplits = length(cvsets)\n",
    "    nlambdas = length(lambdas)\n",
    "    test_loglikelihood = zeros(nlambdas)\n",
    "                    \n",
    "    # prepare the tree structure and the bint \n",
    "    for (k, (λ1, λ2, η1, η2)) in enumerate(lambdas)\n",
    "        for i in 1:nsplits\n",
    "            # get the cv vector with missing data\n",
    "            ytrain = [j in cvsets[i] ? Float64[] : yi\n",
    "                      for (j, yi) in enumerate(y)]\n",
    "\n",
    "            tree = fit2(ytrain, ptr, brks, λ1, λ2, η1, η2, istemporal)               \n",
    "                            \n",
    "            # compute the out-of-sample likelihood\n",
    "            Ntest = 0.0\n",
    "            loglikelihood = 0.0\n",
    "            for j in collect(cvsets[i])\n",
    "                test_eval = y[j]\n",
    "                Ntest += length(test_eval)\n",
    "                ll = log.(predict(tree, sort(test_eval), j) .+ 1e-12)\n",
    "                loglikelihood += sum(ll)\n",
    "            end\n",
    "            loglikelihood /= Ntest\n",
    "                             \n",
    "            test_loglikelihood[k] += loglikelihood / nsplits\n",
    "            dhats = predict(tree, evalpts)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # now choose the best lambdas\n",
    "    best_lambdas = lambdas[argmax(test_loglikelihood)]\n",
    "    best_loglikelihood = maximum(test_loglikelihood)\n",
    "    \n",
    "    # compute validation likelihood\n",
    "    nsims = 100\n",
    "    samples = [rand(model, nsims) for model in models]\n",
    "    lls = [mean(log.(predict(tree, sort(x), j)) .+ 1e-12) for (j, x) in enumerate(samples)]\n",
    "    validation_loglikelihood = mean(lls)\n",
    "\n",
    "    return Dict(\"best_lambdas\" => best_lambdas,\n",
    "                \"cv_loglikelihood\" => best_loglikelihood,\n",
    "                \"val_loglikelihood\" => validation_loglikelihood)\n",
    "end\n",
    "            \n",
    "function get_hypers(method)\n",
    "    lambdas_dict = Dict(\n",
    "        \"fl\" => [(l, 1e-12) for l in range(1e-12, 3.0, length=20)],\n",
    "        \"kal\" => [(1e-12, 10.0^x) for x in range(-3.0, 1.5, length=20)],\n",
    "        \"enet\" => [(l1, 10.0^x) for l1 in range(1e-12, 3.0, length=10)\n",
    "                                for x in range(-3.0, 1.5, length=10)]) \n",
    "    ls = lambdas_dict[method]\n",
    "    hypers = [(λ1, λ2, η1, η2) for (λ1, λ2) in ls for (η1, η2) in ls]\n",
    "    if method == \"enet\"\n",
    "        M = 400\n",
    "    else\n",
    "        M = 100\n",
    "    end\n",
    "    return rand(hypers, M)\n",
    "end\n",
    "           \n",
    "function run_benchmarks(N, pmiss;\n",
    "                        nsims=100,\n",
    "                        nsplits=5,\n",
    "                        tasks=(\"constant\", \"smooth\", \"mixed\"))\n",
    "    experiment_results = []\n",
    "    for task_space in tasks\n",
    "        for task_time in tasks\n",
    "            if task_space == \"mixed\" && task_time == \"mixed\"\n",
    "                outliers = true\n",
    "            else\n",
    "                outliers = false\n",
    "            end\n",
    "            data = [\n",
    "                generate_spt_task(task_space, task_time, N, pmiss, outliers=outliers)\n",
    "                for _ in 1:nsims\n",
    "            ]\n",
    "            for method in (\"fl\", \"kal\", \"enet\")\n",
    "                println(\"Running task_space $task_space task_time $task_time for method $method\")\n",
    "                \n",
    "                lambdas = get_hypers(method)\n",
    "                for (l, D) in ProgressBar(enumerate(data))\n",
    "                    y = vec(D[\"y\"])\n",
    "                    models = vec(D[\"dmodels\"])\n",
    "                    ndata = vec(D[\"ndata\"])\n",
    "                    devals = vec(D[\"devals\"])\n",
    "                    ptr = D[\"ptr\"]\n",
    "                    brks = D[\"brks\"]\n",
    "                    evalpts = D[\"evalpts\"]\n",
    "                    istemporal = D[\"istemporal\"]\n",
    "                    \n",
    "                    cvsets = generate_cvsets(y, nsplits)\n",
    "\n",
    "                    results = cv_fit2(y, evalpts, ptr, brks, istemporal, lambdas, cvsets, models)\n",
    "\n",
    "                    new_result = Dict(\n",
    "                        :experiment => l,\n",
    "                        :task_space => task_space,\n",
    "                        :task_time => task_time,\n",
    "                        :method => method,\n",
    "                        :cv_loglikelihood => results[\"cv_loglikelihood\"],\n",
    "                        :val_loglikelihood => results[\"val_loglikelihood\"])\n",
    "                    push!(experiment_results, new_result)\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return experiment_results\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running task_space smooth task_time smooth for method fl\n"
     ]
    },
    {
     "ename": "InexactError",
     "evalue": "InexactError: Int64(1.584962500721156)",
     "output_type": "error",
     "traceback": [
      "InexactError: Int64(1.584962500721156)",
      "",
      "Stacktrace:",
      " [1] Type at .\\float.jl:703 [inlined]",
      " [2] fit2(::Array{Array{Float64,1},1}, ::Array{Int64,1}, ::Array{Int64,1}, ::Float64, ::Float64, ::Float64, ::Float64, ::Array{Bool,1}) at .\\In[17]:127",
      " [3] cv_fit2(::Array{Array{Float64,1},1}, ::Array{Float64,1}, ::Array{Int64,1}, ::Array{Int64,1}, ::Array{Bool,1}, ::Array{NTuple{4,Float64},1}, ::Array{Set{Int64},1}, ::Array{MixtureModel{Univariate,Continuous,Normal{Float64}},1}) at .\\In[17]:160",
      " [4] #run_benchmarks#260(::Int64, ::Int64, ::Tuple{String,String,String}, ::Function, ::Int64, ::Float64) at .\\In[17]:241",
      " [5] (::getfield(Main, Symbol(\"#kw##run_benchmarks\")))(::NamedTuple{(:nsims, :tasks),Tuple{Int64,Tuple{String,String,String}}}, ::typeof(run_benchmarks), ::Int64, ::Float64) at .\\none:0",
      " [6] top-level scope at In[18]:5"
     ]
    }
   ],
   "source": [
    "N = 30\n",
    "pmiss = 0.1\n",
    "nsims = 1\n",
    "tasks = (\"smooth\", \"constant\", \"mixed\")\n",
    "\n",
    "experiment_results = run_benchmarks(N, pmiss, nsims=nsims, tasks=tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: experiment_results not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: experiment_results not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at ./In[4]:7"
     ]
    }
   ],
   "source": [
    "df = DataFrame(experiment = Int[],\n",
    "               task=String[],\n",
    "               method=String[],\n",
    "               likelihood=Float64[],\n",
    "               rmise=Float64[],\n",
    "               miae=Float64[])\n",
    "for record in experiment_results\n",
    "    push!(df, record)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>experiment</th><th>task</th><th>method</th><th>likelihood</th><th>rmise</th><th>miae</th></tr><tr><th></th><th>Int64</th><th>String</th><th>String</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& experiment & task & method & likelihood & rmise & miae\\\\\n",
       "\t\\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "0×6 DataFrame\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head(df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 0 x 3\n",
      "# Groups:   task [0]\n",
      "# … with 3 variables: task <chr>, method <chr>, likelihood_mean <dbl>\n"
     ]
    }
   ],
   "source": [
    "R\"\"\"\n",
    "df = $df %>% \n",
    "    group_by(task, method) %>%\n",
    "    summarize(likelihood_mean = mean(rmise))\n",
    "print(df)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV.write(\"benchmarks-results-3.csv\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Array} with 12 entries:\n",
       "  \"mean2\"      => [-0.25296, -0.125821, 0.00131861, 0.128458, 0.255598, 0.38273…\n",
       "  \"mean1\"      => [-0.647122, -0.6495, -0.651879, -0.654257, -0.656636, -0.6590…\n",
       "  \"dmodels\"    => MixtureModel{Univariate,Continuous,Normal{Float64}}[MixtureMo…\n",
       "  \"t\"          => [-0.660662, -0.552596, -0.44453, -0.336464, -0.228398, -0.120…\n",
       "  \"ndata\"      => [0 10 … 0 0; 0 10 … 0 0; … ; 0 0 … 0 10; 0 0 … 0 10]\n",
       "  \"y\"          => Array{Float64,1}[[] [-1.10808, -0.637243, -1.39479, -1.48829,…\n",
       "  \"devals\"     => Array{Float64,1}[[0.000247922, 0.000477488, 0.000894049, 0.00…\n",
       "  \"ptr\"        => [1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  630, 660, 690, 720, 750, 7…\n",
       "  \"istemporal\" => Bool[true, true, true, true, true, true, true, true, true, tr…\n",
       "  \"evalpts\"    => [-2.5, -2.44949, -2.39899, -2.34848, -2.29798, -2.24747, -2.1…\n",
       "  \"brks\"       => [1, 31, 61, 91, 121, 151, 181, 211, 241, 271  …  1531, 1561, …\n",
       "  \"means\"      => Tuple{Float64,Float64}[(-1.30778, -0.913622) (-1.19972, -0.80…"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N=30\n",
    "pmiss = 0.8\n",
    "experiment = generate_spt_task(\"smooth\", \"mixed\", N, pmiss; σ=0.3, outliers=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
